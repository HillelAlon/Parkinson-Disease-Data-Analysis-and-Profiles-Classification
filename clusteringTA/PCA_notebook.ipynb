{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup and Logging",
   "id": "6cca96ba58fe4edb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Professional logging setup as per project requirements\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Environment setup complete. Libraries imported.\")"
   ],
   "id": "dc42367ab9842d9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Data Loading\n",
   "id": "7c3c443eaeab0e17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loading the pre-processed dataset specifically prepared for PCA\n",
    "try:\n",
    "    df_pca = pd.read_csv(\"../data/parkinsons_lifestyle_clinical_for_PCA.csv\", index_col=0)\n",
    "    logger.info(f\"Dataset loaded successfully. Shape: {df_pca.shape}\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"Dataset file not found. Please check the file path.\")"
   ],
   "id": "c6fd596557a85264"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Scaling (Standardization)",
   "id": "ae04244f5956ef6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# PCA is scale-sensitive, so we must transform features to a common scale (Z-scores)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_pca)\n",
    "\n",
    "logger.info(\"Feature scaling complete. Data is now normalized.\")\n",
    "print(scaled_data)\n",
    "print(scaled_data.shape)"
   ],
   "id": "40a7d5dad50fce61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Dimensionality Reduction (PCA)",
   "id": "2555e2fd9b724fff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Define the PCA model to reduce data into 3 components\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# 2. Run the PCA on our standardized data\n",
    "pca_results = pca.fit_transform(scaled_data)\n",
    "\n",
    "# 3. Create a new DataFrame for organized results and easy visualization\n",
    "df_pca_output = pd.DataFrame(\n",
    "    data=pca_results,\n",
    "    columns=['PC1', 'PC2', 'PC3'],\n",
    "    index=df_pca.index  # Keeping the original Patient IDs as index\n",
    ")\n",
    "print(df_pca_output)\n",
    "# Professional logging of the process\n",
    "logger.info(f\"PCA execution finished. Features reduced from {df_pca.shape[1]} to 3 components.\")"
   ],
   "id": "e1846d17b3607107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Explained Variance Analysis (Validation)",
   "id": "38cabea9687e3f9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Get the percentage of variance explained by each of the 3 components\n",
    "variance_ratios = pca.explained_variance_ratio_\n",
    "total_variance = np.sum(variance_ratios)\n",
    "\n",
    "# 2. Log the results for documentation\n",
    "logger.info(f\"Variance explained by PC1: {variance_ratios[0]:.2%}\")\n",
    "logger.info(f\"Variance explained by PC2: {variance_ratios[1]:.2%}\")\n",
    "logger.info(f\"Variance explained by PC3: {variance_ratios[2]:.2%}\")\n",
    "logger.info(f\"Total variance captured by all 3 components: {total_variance:.2%}\")\n",
    "\n",
    "# 3. Simple validation check\n",
    "if total_variance > 0.70:\n",
    "    logger.info(\"Validation Success: More than 70% of the information was retained.\")\n",
    "else:\n",
    "    logger.warning(\"Validation Note: Captured variance is below 70%. We might need to consider more components later.\")"
   ],
   "id": "468eaa566d981440"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check how many components are needed to reach 80% variance\n",
    "full_pca = PCA().fit(scaled_data)\n",
    "cumulative_variance = np.cumsum(full_pca.explained_variance_ratio_)\n",
    "\n",
    "# Finding the number of components for 80% threshold\n",
    "n_80 = np.where(cumulative_variance >= 0.80)[0][0] + 1\n",
    "\n",
    "logger.info(f\"To explain 80% of the variance, we would need {n_80} components.\")\n",
    "\n",
    "# Plotting the \"Scree Plot\"\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.8, color='r', linestyle='-')\n",
    "plt.title('How many components do we actually need?')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "50f0e1500cc88884"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scree Plot & Cumulative Variance",
   "id": "55c5f3c7396557a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Run PCA without limiting the number of components to see the full picture\n",
    "full_pca = PCA().fit(scaled_data)\n",
    "cumulative_variance = np.cumsum(full_pca.explained_variance_ratio_)\n",
    "\n",
    "# 2. Find exactly how many components are needed for 80% threshold\n",
    "n_80 = np.where(cumulative_variance >= 0.80)[0][0] + 1\n",
    "logger.info(f\"To explain 80% of the variance, we would need {n_80} components.\")\n",
    "\n",
    "# 3. Visualization: The Scree Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "plt.axhline(y=0.8, color='r', linestyle='-', label='80% Threshold')\n",
    "plt.axhline(y=total_variance, color='g', linestyle='--', label='Current 3 Components')\n",
    "\n",
    "plt.title('Scree Plot: How much information are we capturing?')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "abf7bedaa35d0ba3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # 3D Visualization of Patient Profiles",
   "id": "6981c75fbf4d5919"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Create a 3D figure\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 2. Scatter plot\n",
    "# c=df_pca_output['PC1'] means it will color the points by their PC1 value (looks professional)\n",
    "sc = ax.scatter(df_pca_output['PC1'],\n",
    "                df_pca_output['PC2'],\n",
    "                df_pca_output['PC3'],\n",
    "                c=df_pca_output['PC1'],\n",
    "                cmap='viridis',\n",
    "                s=40,\n",
    "                alpha=0.6)\n",
    "\n",
    "# 3. Labels and Title\n",
    "ax.set_title(\"3D PCA: Parkinson's Patient Profiles\", fontsize=15)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "\n",
    "# 4. Add a color bar\n",
    "plt.colorbar(sc, label='PC1 Gradient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"3D Visualization created using Matplotlib.\")"
   ],
   "id": "5f4c6c05d888dc37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Elbow Method",
   "id": "1f7c03b302f11fe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# 1. Calculate inertia for different numbers of clusters\n",
    "inertia = []\n",
    "K_range = range(1, 11) # Checking from 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(pca_results)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# 2. Plot the Elbow graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o', linestyle='-', color='purple')\n",
    "plt.title('The Elbow Method: Finding Optimal Clusters', fontsize=15)\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia (Error)')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight the \"Elbow\"\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Elbow Method analysis completed.\")"
   ],
   "id": "9e4b6f57c8ea567a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# K-Means Clustering",
   "id": "97eafe9844647d4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Initialize the KMeans model\n",
    "# We choose 4 clusters to look for 4 distinct patient profiles\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "\n",
    "# 2. Fit the model using our PCA results\n",
    "df_pca_output['Cluster'] = kmeans.fit_predict(pca_results)\n",
    "\n",
    "# 3. Log the success\n",
    "logger.info(\"Clustering complete. Patients have been assigned to 4 distinct profiles.\")\n",
    "\n",
    "# 4. Let's see how many patients are in each cluster\n",
    "print(df_pca_output['Cluster'].value_counts())"
   ],
   "id": "a1f34b0395dc1fda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizing the Clusters in 3D",
   "id": "3b52f3474e2807c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Color the points by their Cluster ID (0, 1, 2)\n",
    "scatter = ax.scatter(df_pca_output['PC1'],\n",
    "                     df_pca_output['PC2'],\n",
    "                     df_pca_output['PC3'],\n",
    "                     c=df_pca_output['Cluster'], # This is the magic line!\n",
    "                     cmap='Set1', # A colorful palette for distinct groups\n",
    "                     s=40,\n",
    "                     alpha=0.8)\n",
    "\n",
    "ax.set_title(\"Identified Patient Profiles (4 Clusters)\", fontsize=15)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "\n",
    "# Add a legend to show which color is which Cluster\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"3D Cluster Visualization created successfully.\")"
   ],
   "id": "9e543fdd987f5748"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cluster Profiling",
   "id": "a0b99ad02c0f281d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Add the Cluster labels back to the ORIGINAL dataframe (the one with real units)\n",
    "df_pca['Cluster'] = df_pca_output['Cluster']\n",
    "\n",
    "# 2. Calculate the mean (average) for each variable per cluster\n",
    "cluster_profiles = df_pca.groupby('Cluster').mean()\n",
    "\n",
    "# 3. Display the results\n",
    "print(\"Profiles for each Cluster (Mean Values):\")\n",
    "display(cluster_profiles)\n",
    "\n",
    "# 4. Save the results to a CSV file to use in your presentation slides\n",
    "\n",
    "cluster_profiles.to_csv(\"patient_profiles_summary.csv\")\n",
    "logger.info(\"Cluster profiling complete. Summary saved to CSV.\")"
   ],
   "id": "c152aeaf54a2fcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creation of a heat map for clusters\n",
    "We normalized the mean values across clusters using Z-score standardization to allow for a direct comparison. In this heatmap, a value of 0 represents the overall population mean. Red cells indicate values significantly above the average, while blue cells represent values below the average."
   ],
   "id": "64b42af868003185"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cluster_profiles_norm = (cluster_profiles - cluster_profiles.mean()) / cluster_profiles.std()\n",
    "\n",
    "# Creating heat map\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_profiles_norm, annot=cluster_profiles.round(2), cmap='RdYlBu_r', center=0)\n",
    "\n",
    "plt.title(\"Patient Profiles Characteristics (Heatmap)\", fontsize=16)\n",
    "plt.ylabel(\"Cluster ID\")\n",
    "plt.xlabel(\"Medical & Lifestyle Features\")\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Visual profile summary created.\")"
   ],
   "id": "3df61c95836f8a64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4af7ce2dff2bf06d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
